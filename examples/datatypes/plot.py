#!/usr/bin/env python3

import csv
import argparse
import re
import numpy as np
import pandas as pd
import scipy.stats as st
import sys
from math import ceil

from os import listdir
from os.path import isfile, join, isdir

from plot_lib import *

parser = argparse.ArgumentParser(
    prog='plot.py',
    description='Plot data generated by the datatypes benchmark',
    epilog='Report bugs to Pengcheng Xu <pengxu@ethz.ch>.'
)

parser.add_argument('--data_root', help='root of the CSV files from the datatypes benchmark', default=None)

args = parser.parse_args()

def dim_to_gflops(dim, iter, elapsed):
    return 2 * dim ** 3 * iter / elapsed / 1e9
def rtt_to_mbps(sbuf_sz, num_parallel, rtt):
    return sbuf_sz * 8 * num_parallel / rtt / 1e6

slmp_payload_size = 1462 // 4 * 4
elem_size = 110592 # one element
data_pkl = 'data.pkl'

def consume_trials(key, full_key, dt_idx, trials):
    # https://stackoverflow.com/a/42837693/5520728
    def append_iperf(par, mbps):
        global data
        entry = pd.DataFrame.from_dict({
            'parallelism': [par],
            'mbps_iperf': [mbps],
        })
        data = pd.concat([data, entry], ignore_index=True)

    def append_mpich(par, sbuf_size, is_vanilla, mbps, dtype_idx):
        global data
        entry = pd.DataFrame.from_dict({
            'parallelism': [par],
            'msg_size': [sbuf_size],
            'is_vanilla': [is_vanilla],
            'mbps_mpich': [mbps],
            'datatype': [dtype_idx],
        })
        data = pd.concat([data, entry], ignore_index=True)

    def append_overlap(par, sbuf_size, dtype_idx, mbps_ref, mbps_overlap, gflops_theo, gflops_ref, gflops_overlap, overlap_ratio):
        global data
        entry = pd.DataFrame.from_dict({
            'parallelism': [par],
            'msg_size': [sbuf_size],
            'datatype': [dtype_idx],
            'mbps_ref': [mbps_ref],
            'mbps_overlap': [mbps_overlap],
            'gflops_theo': [gflops_theo],
            'gflops_ref': [gflops_ref],
            'gflops_overlap': [gflops_overlap],
            'overlap_ratio': [overlap_ratio],
        })
        data = pd.concat([data, entry], ignore_index=True)

    def append_row(num, type, value):
        global data
        entry = pd.DataFrame.from_dict({
            full_key: [num],
            'type': [type],
            'value': [value],
        })
        data = pd.concat([data, entry], ignore_index=True)

    if key == 'i':
        # iperf theoretical data
        iperf_dat = [9.22, 10.4, 8.36, 8.49, 7.75, 8.66, 7.63, 8.60, 8.70, 7.89, 7.92, 8.16, 7.87, 8.07, 7.31, 7.78]
        for par, gbps in enumerate(iperf_dat):
            append_iperf(par + 1, gbps * 1000)

        return

    for t in trials:
        base_regex = key + r'-([0-9]+)\.csv'
        baseline = False
        if m := re.match(base_regex, t):
            val = m.group(1)
        elif m := re.match('b' + base_regex, t):
            val = m.group(1)
            baseline = True
            vanilla = False
        elif m := re.match('v' + base_regex, t):
            val = m.group(1)
            baseline = True
            vanilla = True
        else:
            continue
        val = float(val)

        fname = join(args.data_root, dt_idx, t)
        print(f'Consuming {fname}')
        with open(fname, 'r') as f:
            reader = csv.reader(f)
            if baseline:
                # MPICH
                assert next(reader) == ['elements', 'parallel', 'streambuf_size', 'types_idx', 'types_str']
                *params, types_idx, types_str = next(reader)
                elem, par, sbuf_size = map(int, params)

                assert next(reader) == []
                assert next(reader) == ['elapsed']
                for dat in reader:
                    elapsed, = map(float, dat)
                    append_mpich(par, sbuf_size, vanilla, rtt_to_mbps(sbuf_size, par, elapsed), types_idx)

            else:
                assert next(reader) == ['gflops_theo', 'gflops_ref', 'dim', 'streambuf_size', 'par', 'types_idx']
                *params, types_idx = next(reader)
                tg, rg, dim, sbuf_size, par = map(float, params)
                num_packets = ceil(sbuf_size / slmp_payload_size)

                # append_row(val, dgemm_theo_label, tg)
                # append_row(val, dgemm_ref_label, rg)
                assert next(reader) == []

                assert next(reader) == ['dgemm', 'iters', 'dt_ref_rtt',
                                        'dt_ref_pkt', 'dt_ref_msg', 'dt_rtt', 'dt_pkt', 'dt_msg']
                for data_tuple in reader:
                    # dgemm w/ dt, dt w/o dgemm, dt w/ dgemm
                    # RTT in float seconds
                    dgemm_overlap, dgemm_iter, dt_ref_rtt, dt_ref_pkt, dt_ref_msg, dt_rtt, dt_pkt, dt_msg = map(float, data_tuple)
                    dt_pkt *= num_packets
                    dt_ref_pkt *= num_packets

                    append_overlap(par, sbuf_size, types_idx,
                        rtt_to_mbps(sbuf_size, par, dt_ref_rtt),
                        rtt_to_mbps(sbuf_size, par, dt_rtt),
                        tg, rg,
                        dim_to_gflops(dim, dgemm_iter, dgemm_overlap),
                        dgemm_overlap / dt_rtt)

if args.data_root:
    datatypes_indices = [d for d in listdir(args.data_root) if isdir(join(args.data_root, d))]

    data = pd.DataFrame(columns=[
        'parallelism',
        'msg_size',
        'is_vanilla',
        'datatype',
        'gflops_theo',
        'gflops_ref',
        'gflops_overlap',
        'mbps_iperf',
        'mbps_mpich',
        'mbps_ref',
        'mbps_overlap',
        'overlap_ratio'])
    consume_trials('i', 'parallelism', None, None)

    for d in datatypes_indices:
        trials = [f for f in listdir(join(args.data_root, d)) if isfile(join(args.data_root, d, f))]
        consume_trials('p', 'parallelism', d, trials) # num_parallel is the key value

    data.to_pickle(data_pkl)

set_style()

dp: pd.DataFrame = pd.read_pickle(data_pkl)

lb = TitledLegendBuilder()

# title: [(name, column, {filter_key: filter_val})]
tasks_dt_tput = {
    '': [
        ('IPerf3', 'mbps_iperf', {}),
    ],
    'Baseline MPICH': [
        ('C. Simple', 'mbps_mpich', {'is_vanilla': True, 'datatype': '1'}),
        ('C. Complex', 'mbps_mpich', {'is_vanilla': True, 'datatype': '0'}),
        ('F. Simple', 'mbps_mpich', {'is_vanilla': False, 'datatype': '1'}),
        ('F. Complex', 'mbps_mpich', {'is_vanilla': False, 'datatype': '0'}),
    ],
    'Datatypes': [
        ('Ref. Simple', 'mbps_ref', {'datatype': '1'}),
        ('Ref. Complex', 'mbps_ref', {'datatype': '0'}),
        ('Ovlp. Simple', 'mbps_overlap', {'datatype': '1'}),
        ('Ovlp. Complex', 'mbps_overlap', {'datatype': '0'}),
    ],
}

# diagram 1: 1 row, 2 cols
#   plot 1: dt tput - degree of parallelism
#   plot 2: dt tput - length of message
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=figsize(5/3), sharey=True)

ax1.grid(which='both')
ax2.grid(which='both')
ax1.set_ylabel('Throughput (Mbps)')
ax1.set_yscale('log')
ax2.set_yscale('log')
ax1.set_xlabel('Degree of Parallelism')
ax2.set_xlabel('Message Length (B)')

ax1.label_outer()
ax2.label_outer()

def line_x(x_col, ax, lb, y_col):
    x = []
    y_median = []
    y_left = []
    y_right = []
    for xx, rows in trial.groupby(x_col):
        # print(f'plotting {xx} {rows}')
        x.append(xx)
        vals = rows[y_col].dropna()
        # print(y_col, rows[y_col])
        med = vals.median()
        y_median.append(med)
        if len(vals) > 1:
            bootstrap_ci = st.bootstrap((vals,), np.median, confidence_level=0.95, method='percentile')
            ci_lo, ci_hi = bootstrap_ci.confidence_interval
            y_left.append(med - ci_lo)
            y_right.append(ci_hi - med)
        else:
            y_left.append(0)
            y_right.append(0)

    if lbl == 'IPerf3':
        # print(x, y_median)
        ax.plot(x, y_median, linestyle='--', color='purple')
    else:
        ax.errorbar(x, y_median, yerr=(y_left, y_right), ecolor='black')
    lb.push(cat, lbl, ax.lines[-1])

for cat, lines in tasks_dt_tput.items():
    # print(cat, lines)
    for lbl, col, filter_kv in lines:
        trial = dp

        for k, v in filter_kv.items():
            trial = trial[trial[k] == v]

        line_x('parallelism', ax1, lb, col)
        line_x('msg_size', ax2, lb, col)
    
lb.draw(fig)
fig.savefig('datatypes-tput.pdf')

# diagram 2: 1 row, 2 cols
#   plot 1: gemm tput - length of message
#   plot 2: overlap ratio - length of message

fig.savefig('datatypes-overlap.pdf')